model:
  architecture:
    encoder: GoogleNet
    decoder: Linear
  features:
    in_channels: 1
    number_classes: 10

algorithm:
  name: train
  device: cuda:0
  epochs: 20
  seed: 42

dataset:
  name: MNIST
  batch_size: 64
  sizes:
    train_size: 0.8
    valid_size: 0.1
    test_size: 0.1
  transform: ./transform.yaml

save:
  logs:
    path: ./logs
  checkpoints:
    path: ./checkpoints
    save_every: 5

optimizer:
  name: RAdam
  type: pytorch
  params:
    lr: 0.001
    weight_decay: 0.00001

scheduler:
  name: PolynomialLRDecay
  type: custom
  params:
    max_decay_steps: 20
    end_learning_rate: 0.0005
    power: 0.9

loss_function: L1Loss
metrics: [precision, recall, f1]

wandb:
  project_name: OpenNN
  run_name: cuda-run
  metrics: [precision, recall]
